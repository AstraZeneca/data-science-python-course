{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b4c044",
   "metadata": {},
   "source": [
    "# Week 3 - Key concepts in statistics and machine learning\n",
    "\n",
    "This tutorial is a no-code tutorial that will introduce you to the very fundamendals of statistics and machine learning. The definitions and techniques introduced here will be useful later in this course where we apply these techniques in real-life situations.\n",
    "\n",
    "### Aims\n",
    "\n",
    "- Statistics\n",
    "    - Define statistics and it's purpose\n",
    "    - Define the Type I, Type II errors and the power of a statistical test\n",
    "    - Differentiate between the H<sub>0</sub> and H<sub>1</sub>\n",
    "    - Understand what the p-value is and how it is calculated\n",
    "    - Decide whether to reject the null hypothesis or not\n",
    "\n",
    "\n",
    "\n",
    "- Machine learning\n",
    "     - Distinguish between different types of machine learning problems\n",
    "     - Understand the general framework of linear regression\n",
    "     - Understand the general framework of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761d76b",
   "metadata": {},
   "source": [
    "## Key concepts in statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf5c7f",
   "metadata": {},
   "source": [
    "Statistics is a branch of applied mathematics that deals with collecting, organising, analysing, reading and presenting data. It can also be furtherly divided into:\n",
    "\n",
    "- **Data collection**: With what crietria are the data collected. \n",
    "- **Descriptive statistics**: How the data can be summarized and described.\n",
    "- **Inferential statistics**: Using the data to make predictions.\n",
    "\n",
    "Let's see all this steps in action: Assume that there is an **imaginary** organization where the SET is trying to estimate how many days each employ aims to spend on-site (assuming there are two regions, site A and site B). The idea is to check whether the same pattern is observed in both sites.\n",
    "\n",
    "Admin stuff is working very hard to gather accurate information and be able to predict the number of days the employees aim too spend on the site. In order to do that, they contact people by mail to ask them about their intentions. One key thing to address is <ins> how should they contact the public in order to ensure that people from different parts of the company are equally represented</ins> (*Data Collection*).\n",
    "\n",
    "Once the data have been collected, the admin stuff can have an initial idea about some key meassures. For instance, <ins> how do employees in a specific department intent to return to the site or how do people of a specific age group changed their working preferences after COVID? <ins> (*Descriptive statistics*).\n",
    "    \n",
    "Once the results have been summarized and described, they can be used for prediction. For example, based on all the information collected from the emails, <ins> can we predict if the number of days that the employees want to work on site is the same between the two sites? <ins> (*Inferential statistics*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4e33d",
   "metadata": {},
   "source": [
    "### From sample to population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddac3f",
   "metadata": {},
   "source": [
    "In the above example, the big question is to predict the number of hours that employees aim to spend on site in each region. But as in the majority of the real-life problems, we will only have access to a fraction of the whole population (*sample*) rather than the whole population.\n",
    "\n",
    "**Statistics is the art of using the sample to make inference about the population**\n",
    "\n",
    "\n",
    "<img src=\"../img/sample_to_population.jpg\"/>\n",
    "\n",
    "*Source: http://korbedpsych.com/R06Sample.html*\n",
    "\n",
    "\n",
    "\n",
    "We could only rely on the collected samples and make a verdict like: *In the sample we collecetd, we got that on site A, employess aim to spend 3 days/week in the office, while on site B it's 2.3 days/week, thus we declare that site A employees want to get back on site more days!*. While this might be a logical assumtion to follow, it completely ignores the following question:\n",
    "\n",
    "*What if we just got more willing site A employees just by chance?*\n",
    " \n",
    "In order to make inference about the whole population from our sample, we need to make some assumptions about the whole population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d97854",
   "metadata": {},
   "source": [
    "### Defining a hypothesis: H<sub>0</sub> and H<sub>1</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33a8b7",
   "metadata": {},
   "source": [
    "Every problem in inferential statistics starts with a hypothesis. *A statistical hypothesis is a hypothesis that is testable on the basis of observed data modelled, as the realised values folowoing a set of assumptions.*\n",
    "\n",
    "In all the problems of this nature that we encounter here, there are two kinds of hhypotheses:\n",
    "\n",
    "- **H<sub>0</sub>**, or the **null hypothesis**: The default hypothesis, and the the quantity measured is usually equal to zero (null). \n",
    "- **H<sub>1</sub>**, or the **alternative hypothesis**: A hypothesis that contradicts the null hypothesis.\n",
    "\n",
    "The alternative hypothesis can fully or partialy contradict the null hypothesis. Coming back to our polling example:\n",
    "\n",
    "Some formulation of the null vs the alternative hypothesis could be:\n",
    "\n",
    "- *Option 1*:\n",
    "    - H<sub>0</sub>: The mean number of hours that employees want to spend on-site on site A and B are (statistically) the same\n",
    "    - H<sub>1</sub>: The mean number of hours that employees want to spend on-site on site A are (statistically) **greater** than the mean number of hours that employees want to spend on-site on site A\n",
    "\n",
    "- *Option 2*:\n",
    "    - H<sub>0</sub>: The mean number of hours that employees want to spend on-site on site A and B are (statistically) the same\n",
    "    - H<sub>1</sub>: The mean number of hours that employees want to spend on-site on site A are (statistically) **lower** than the mean number of hours that employees want to spend on-site on site A\n",
    "    \n",
    "- *Option 3*:\n",
    "    - H<sub>0</sub>:  The mean number of hours that employees want to spend on-site on site A and B are (statistically) the same\n",
    "    - H<sub>1</sub>: The mean number of hours that employees want to spend on-site on site A are (statistically) **different** than the mean number of hours that employees want to spend on-site on site A\n",
    "\n",
    "\n",
    "Depending on the scientific question, the formulation of the null and alternative hypothesis can change. One thing that remains constant in the majority of hypotheses formulation is that the null hypothesis **should stay null**. This is due to mathematical convinience, as it is easier to model.\n",
    "\n",
    "\\\n",
    "&nbsp;\n",
    "\n",
    "Let's take a different example. A scientist is interested in investigating whether the light color (blue or red) has an effect on the plant growth. The scientists meassures the plants'growth in cm. Thus, the two hypothesis formulated here could be:\n",
    "\n",
    "- H<sub>0</sub>: Light color has no effect on plant growth\n",
    "- H<sub>1</sub>: Light color affects plant growth\n",
    "\n",
    "But, where is the zero in this null hypothesis? The zero is hidden in the more mathematical formulation of the above hypotheses. A data scientist/statistician would formulate the above hypotheses as :\n",
    "\n",
    "- H<sub>0</sub>: The difference in the growth of plants under blue light and the plants under red light is 0\n",
    "- H<sub>1</sub>: The difference in the growth of plants under blue light and the plants under red light is different than 0\n",
    "\n",
    "<img src=\"../img/null_vs_alternative_hypothesis.png\" width=\"600\">\n",
    "\n",
    "*Source: https://sciencenotes.org/null-hypothesis-examples/*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512d08d",
   "metadata": {},
   "source": [
    "### Errors and its types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dac2db",
   "metadata": {},
   "source": [
    "A perfect test would have zero false positives and zero false negatives. However, statistical methods are probabilistic, and it cannot be known for certain whether statistical conclusions are correct. Whenever there is uncertainty, there is the possibility of making an error. Considering this nature of statistics science, all statistical hypothesis tests have a probability of making type I and type II errors.\n",
    "\n",
    "- The **type I error rate or significance level** is the probability of rejecting the null hypothesis given that it is true. It is denoted by the Greek letter α (alpha) and is also called the alpha level. Usually, the significance level is set to 0.05 (5%), implying that it is acceptable to have a 5% probability of incorrectly rejecting the true null hypothesis.\n",
    "\n",
    "- The **rate of the type II error** is denoted by the Greek letter β (beta) and is the probability of don't rejecting the null hypothesis while it is false.\n",
    "\n",
    "These two types of error rates are traded off against each other: for any given sample set, the effort to reduce one type of error generally results in increasing the other type of error.\n",
    "\n",
    "<img src=\"../img/error_types.PNG\">\n",
    "\n",
    "*Source: Wikipedia*\n",
    "\n",
    "Another propability that is useful when designing a test is the **statistical power** of a test, which is also called the **probability of correct rejection**. It is calculated as 1-β (Type II error). The higher the statistical power for a given experiment, the lower the probability of making a Type II error. That is the higher the probability of detecting an effect when there is an effect. In fact, the power is precisely the inverse of the probability of a Type II error.\n",
    "\n",
    "It is common to design experiments with a statistical power of 80% or better, e.g. 0.80. This means a 20% probability of encountering a Type II area. This different to the 5% likelihood of encountering a Type I error for the standard value for the significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af0576",
   "metadata": {},
   "source": [
    "### The statistic fucntion and the p-value of the test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af58985",
   "metadata": {},
   "source": [
    "Now that we have defined some key definitions of a test, we will explore how a test is performed and how decisions are made based on its output. \n",
    "\n",
    "One of the most important quantities of a test is the **statistic function**.  It is a function of the data (and possibly other parameters) that follows a pre-defined and known distribution. It is considered as a numerical summary of a data-set that reduces the data to one value that can be used to perform the hypothesis test. Examples of various statistic fucntions can be found in this [Wikipedia article](https://en.wikipedia.org/wiki/Test_statistic).\n",
    "\n",
    "As an example, we present the statistic function of the *two-independent samples t-test*. This test is used when we want to compare the means of two independent populations (like in our on-site employees example, where we want to calculate and compare the mean number of hours people aim to spend on-site on each site). The statistic function is\n",
    "\n",
    "$$ t = \\frac{(\\bar{x_1} - \\bar{x_2}) - d}{\\sqrt{\\frac{s{_1}^2}{n_1} + \\frac{s{_2}^2}{n_2}}} $$\n",
    "\n",
    "and is symbolized by $t$. A small legend:\n",
    "\n",
    "- $\\bar{x_1}$: The mean number of hours for employees on site A in the sample\n",
    "- $\\bar{x_2}$: The mean number of hours for employees on site B in the sample\n",
    "- $\\bar{s{_1}^2}$: The variance of the number of hours for employees on site A in the sample\n",
    "- $\\bar{s{_2}^2}$: The variance of the number of hours for employees on site B in the sample\n",
    "- $n_1$: Number of people asked from site A in the sample\n",
    "- $n_2$:Number of people asked from site B in the sample\n",
    "- $d$: The desired difference we want in our null hypothesis (in this case, we assumed equality, so this is 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a2c03",
   "metadata": {},
   "source": [
    "Once we have calculated the value of the statistic funtion, we can calculate how \"likely\" this value is, as we have already defined a distribution for our statistic function. Thus, we want to see how far or close we are from the tolerance level we have set (*remember α, this is our tolerance*).\n",
    "\n",
    "\n",
    "The area under any probability distribution is equal to 1. And as the x-axis is ordered, we can calculate the probability the value we observed is greater or lower than the value of the tolerance we have set. \n",
    "\n",
    "<img src=\"../img/normal_distribution.png\">\n",
    "\n",
    "*Source: https://blogs.sas.com/content/iml/2019/07/22/extreme-value-normal-data.html*\n",
    "\n",
    "But depending on the design of our alternative hypothesis, we want to allocate our tolerance accordingly. Let's go back to our pollsters example. Here are the 3 different optiions we preseneted for the alternative hypothesis:\n",
    "\n",
    "In the first scenario, we only reject the null hypothesis when the percentage of votes for Candidate A is (statistically) **greater** than Candidate's B. This means that we can allocate our tolerance **only on the right part of the distribution**, and all of the 5% will be alocated on the right (for option 2, we allocate out tolerance on the left part of the distribution).\n",
    "\n",
    "For option 3, we want to allocate our tolerance both in the right and the left tail of our distribution. Assuming that we have a tolerance equal to α, we are spliting the tolerance equally as: α/2 on the right and α/2 on the left.\n",
    "\n",
    "<img src =\"../img/rejection_area.jpg\">\n",
    "\n",
    "For any model our statistic function follows, the probability of observing a value more extereme (either lower or higher) than we have observed (the actual value of the $t$ fucntion in this case) is called **p-value**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ed882",
   "metadata": {},
   "source": [
    "### To reject, or not to reject?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa81e17",
   "metadata": {},
   "source": [
    "At this stage we, have calculated everything; the t-statistic, the p-value, and we have a pre-set α value. But how are we making a decision about whether to reject or not the null hypothesis?\n",
    "\n",
    "*Be aware, we **NEVER** accept the null hypothesis, we simply do not have enough evidence to reject it!*\n",
    "\n",
    "The p-value is an indication of how \"strong\" (or likely) H<sub>0</sub> is. Thus, if the p-value **is greater than the tollerance level α** then our indication towards H<sub>0</sub> is strong and we cannot reject it. In contrast, if the p-value is lower than α, then we can safely reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1df850",
   "metadata": {},
   "source": [
    "## Key concepts in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a761b29",
   "metadata": {},
   "source": [
    "Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data.\n",
    "\n",
    "*The major difference between machine learning and statistics is their purpose. Machine learning models are designed to make the most accurate predictions possible. Statistical models are designed for inference about the relationships between variables.*\n",
    "\n",
    "Machine learning is all about results, it is likely working in a company where your results are characterized solely by your how good they are. Whereas, statistical modeling is more about finding relationships between variables and the significance of those relationships, whilst also catering for prediction.\n",
    "\n",
    "<img src=../img/machine_learning.png>\n",
    "\n",
    "*Source: https://datascience.stackexchange.com/questions/42621/data-science-related-funny-quotes*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e26337",
   "metadata": {},
   "source": [
    "### Types of machine learning problems\n",
    "\n",
    "Not all machine learning problems are created equal, nor they use the same methods to make predictions. Given the problems nature, available data and the reserahcer's goal, a machine learning problem can fall into one of the following categories:\n",
    "\n",
    "- **Supervised learning**: Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. In supervised learning, each example is a pair consisting of an input and a desired output value. A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations. \n",
    "\n",
    "    The most widely used learning algortithms are:\n",
    "    - Support-vector machines\n",
    "    - **Linear regression**\n",
    "    - **Logistic regression**\n",
    "    - Naive Bayes\n",
    "    - Decision trees\n",
    "    - K-nearest neighbor algorithm\n",
    "    - Neural networks (Multilayer perceptron)\n",
    "\n",
    "\n",
    "- **Unsupervised learning**: Unsupervised learning (UL) is a type of machine learning in which the algorithm is not provided with any pre-assigned labels or scores for the training data. As a result, unsupervised learning algorithms must first self-discover any naturally occurring patterns in that training data set. Advantages of unsupervised learning include a minimal workload to prepare and audit the training set, in contrast to supervised learning techniques where a considerable amount of expert human labor is required to assign and verify the initial tags, and greater freedom to identify and exploit previously undetected patterns.\n",
    "\n",
    "     The most widely used learning algortithms are:\n",
    "    - Hierarchical clustering\n",
    "    - K-means\n",
    "    - Mixture models\n",
    "\n",
    "\n",
    "- **Reinforcement learning**:Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef6bd3",
   "metadata": {},
   "source": [
    "### A brief introduction to linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f89d6",
   "metadata": {},
   "source": [
    "**Linear regression** is a linear approach for modelling the relationship between a collection of explanatorty variables (also known as predictors or independent variables) and a scalar value (also known as dependent variables or response). The case of one explanatory variable is called *simple linear regression*; for more than one, the process is called *multiple linear regression*.\n",
    "\n",
    "In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models. The most basic linear model is\n",
    "\n",
    "$$ y_i = \\beta_0 + \\beta_1 * x_i + \\epsilon_i $$\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "- $y$ is the **dependent** variable\n",
    "- $x$ is the **independent** variable\n",
    "- $\\beta_0 \\; \\text{and} \\; \\beta_1$ are the coefficients of the regression\n",
    "- $\\epsilon_i $ is the error term (*sometimes also called noise*)\n",
    "\n",
    "<img src=\"../img/linear_least_squares.png\">\n",
    "\n",
    "*Source: Wikipedia*\n",
    "\n",
    "*The observations (red) are assumed to be the result of random deviations (green) from an underlying relationship (blue) between a dependent variable (y) and an independent variable (x).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d37d5b",
   "metadata": {},
   "source": [
    "While linear regression is the way-to-go for many problems involving a relationship between numerical variables, there are some underlying assumptions behind these model. These include:\n",
    "\n",
    "- **Linearity**:  This means that the mean of the response variable is a linear combination of the parameters (regression coefficients) and the predictor variables (more on this on the ML tutorial).\n",
    "- **Lack of perfect multicollinearity in the predictors**: For standard least squares estimation methods, the predictors (if more than one)must have full column rank p; otherwise perfect multicollinearity exists in the predictor variables, meaning a linear relationship exists between two or more predictor variables.\n",
    "- A few more that require further deep dive in statistical theory and they are outside the scope of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16898e9",
   "metadata": {},
   "source": [
    "The purpose of linear regression is to estimate the values of $\\beta_p, \\; p= 0,1,...,M$. This will give a model in which whenever we feed it a value for every predictor, it will be able to *predict* a value for the target variable $y$. Let's go through an example:\n",
    "\n",
    "Let's assume that we want to model the relationship between the time a student studies, the time his sleeps and his final exams grades. In this case, we want to predict the exam grade, so the grade is the **dependent variable**, while the other two variables are the **independent** variables. Ideally, we we end up with a model in the follwoing form:\n",
    "\n",
    "$$ \\text{final exam grade} = \\beta_{0} + \\beta_{1} * \\text{how many hours a student studied} + \\beta_{2}* \\text{how many times a  student slept} $$\n",
    "\n",
    "The interpretation of the $ \\beta $ are the following:\n",
    "\n",
    "- $\\beta_0$: What would be the grade of a student that spent 0 hours in studying and sleeping (extreme case)\n",
    "- $\\beta_1$: How much the grade of a student would improve if he added ONE extra hour of **studying** in his schedule\n",
    "- $\\beta_2$: How much the grade of a student would improve if he added ONE extra hour of **sleep** in his schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ef388",
   "metadata": {},
   "source": [
    "### A brief introduction to logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734e39d",
   "metadata": {},
   "source": [
    "In many cases, the problem that we aim to solve is slightly different that he one we solved with the linear regression. Let's take the students example we posed above. Instead of predicting the exact grade of each student, we want to predict if the student *pass or fails* the exam. \n",
    "\n",
    "This turns our problem into a *classification* problem; we want to classify each data point (in this case, the students) in one of the two classes. This class of problems give birth to the **logistic regression** model.\n",
    "\n",
    "The logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. Each datapoint would be assigned a probability between 0 and 1, with a sum of one for each of the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9650be6",
   "metadata": {},
   "source": [
    "Similar to linear regresison, we want to use our predictors (the **independent** variable(s)) to make predictions about the **dependent** varriable, which in this case is either 0 or 1. Istead of trying to estimate an exact value, we model the *odds*, which translate to *how more probable is for a data point to belong on class 1 rather than class 0*? This can be mathematically modelled as:\n",
    "\n",
    "$$ \\text{odds} = \\frac{p}{1-p} $$\n",
    "\n",
    "where $p$ is the probability of a data point belonging to class 1. To make the connection with the linear regression (on its simpler case), the final form of the model is:\n",
    "\n",
    "$$ log_b(\\frac{p}{1-p}) = \\beta_0 + \\beta_1*x_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fcdda",
   "metadata": {},
   "source": [
    "and with simple algebraic operation, we can calculate the probability of class one as:\n",
    "\n",
    "$$ p = \\frac{b^{\\beta_0 + \\beta_1*x_1}}{b^{\\beta_0 + \\beta_1*x_1} + 1}$$\n",
    "\n",
    "where $b$ is the base of the logarithm we choose (most common choices are 2 or 10, no need to worry about it).\n",
    "\n",
    "\n",
    "<img src=\"../img/logistic_curve.jpeg\">\n",
    "\n",
    "*Source: Wikipedia*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9417c",
   "metadata": {},
   "source": [
    "**Remember that th elogistic model returns probabilities and not class assignment!** Many people assume that this model returns class assignments, e.g. in the students example, whether the student pass/fail the exam. \n",
    "\n",
    "The researcher usually sets their own threshold (usually 0.5, unless there are some condition outside the scope of this course). \n",
    "\n",
    "Finally, another difference between the linear and the logistic regression is the interpretation of the $\\beta$ coefficients. In logisti regression:\n",
    "\n",
    "- $\\beta_0$:  It is the log-odds of the event that the data points belogning in class 1 , when all the other predictors are set to 0.\n",
    "- $\\beta_i$: This is number that the **logarith of odds** are increased when the value of the predictor i increases by 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
